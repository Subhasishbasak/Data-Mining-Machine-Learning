{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subhasishbasak/Data-Mining-Machine-Learning/blob/master/Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Image classification Using Convolution Neural Network\n",
        "# Final Project / MDS201803"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzLKpmZICaWN",
        "colab": {}
      },
      "source": [
        "# Basic Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "### Importing the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "The Fashion MNIST dataset contains $60000$ training images and $10000$ test images. Each image has a shape of 28 x 28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zW5k_xz1CaWX",
        "colab": {}
      },
      "source": [
        "train_images.shape, test_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Data Pre-processing\n",
        "\n",
        "Since each pixel value in the images are in the range $[0, 255]$. We transform the images into Gray-scale by dividing each pixel value by 255. \n",
        "<br> Also we need to reshape the data in order to feed it into the CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW5WzIPlCaWv",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWVw7vdLwB-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wpHdpj00iN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gm-wB2lwCCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Building the Convolutional Neural Network model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Setting up the layers\n",
        "In our CNN model we add the following layers :\n",
        " - First Convolution Layer\n",
        " - Activation Layer : **ReLU**\n",
        " - Max Pooling Layer \n",
        " - Dropout layer : prob 0.3\n",
        " - Second Convolution Layer\n",
        " - Activation Layer : **ReLU**\n",
        " - Max Pooling Layer \n",
        " - Dropout layer : prob 0.3\n",
        " - Fully Connected layer - 256 neurons\n",
        " - Activation Layer : **ReLU**\n",
        " - Dropout layer : prob 0.3\n",
        " - Classification layer – 10 neurons\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ODch-OFCaW4",
        "colab": {}
      },
      "source": [
        "# Build the model.\n",
        "\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "      Conv2D(32, kernel_size=(3, 3), strides= (1,1), activation='relu', input_shape=(28, 28, 1), kernel_initializer='he_normal'), \n",
        "      MaxPooling2D(pool_size=(2, 2), strides= (2,2)),   \n",
        "      Dropout(0.3),\n",
        "      Conv2D(64, kernel_size=(3, 3), strides= (1,1), activation='relu'),\n",
        "      MaxPooling2D(pool_size=(2, 2), strides= (2,2)),\n",
        "      Dropout(0.3),\n",
        "      Flatten(),\n",
        "      Dense(256, activation='relu'),\n",
        "      Dropout(0.3),\n",
        "      Dense(10, activation='softmax'),\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J8m4_KSHX_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_cnn = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp6i8bzODrIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_cnn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "### Compilation of the model\n",
        "\n",
        "We specify the following details before training the modelin the *compile* step:\n",
        "\n",
        "* **Loss function** — Sparse Categorical Cross entropy\n",
        "* **Optimizer** — adam\n",
        "* **Metrics** — For evaluating the model's performance we use the *accuracy* metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lhan11blCaW7",
        "colab": {}
      },
      "source": [
        "my_cnn.compile(\n",
        "  loss = 'sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        "  optimizer='adam'\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "Training the neural network model requires the following steps:\n",
        "\n",
        " -  To train the model we feed the training data to the model i.e.  `train_images` and `train_labels` arrays.\n",
        "\n",
        " - The model's performance is validated using the test data i.e. using `test_images` and `test_labels` array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AxqDjrLRd7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained_model = my_cnn.fit(\n",
        "                train_images,\n",
        "                train_labels,\n",
        "                epochs=25,\n",
        "                validation_data=(test_images, test_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VflXLEeECaXC",
        "colab": {}
      },
      "source": [
        "test_loss, test_acc = my_cnn.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wCpr6DGyE28h"
      },
      "source": [
        "### Evaluating test Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVAPxcZGRd2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy = trained_model.history['accuracy']\n",
        "val_accuracy = trained_model.history['val_accuracy']\n",
        "loss = trained_model.history['loss']\n",
        "val_loss = trained_model.history['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIGhHoJ5bmL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot loss\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(loss, color='blue', label='train')\n",
        "plt.plot(val_loss, color='orange', label='test')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUy_VP-5cUwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot accuracy\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(accuracy, color='blue', label='train')\n",
        "plt.plot(val_accuracy, color='orange', label='test')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "We observe that after the final epoch of training the **training accuracy** is $92.8\\%$ compared to the **test accuracy** which is $91.6\\%$. This indicates that the model performs slightly better on the Training data than the Test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_7A5dGQLo0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}