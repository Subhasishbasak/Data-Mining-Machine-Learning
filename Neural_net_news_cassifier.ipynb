{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDS201803<BR>MDS201811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json    \n",
    "raw_data = []\n",
    "with open(r\"C:\\Users\\LENOVO\\Downloads\\SEM2\\DMML\\Assignments\\News-Classification-DataSet\\News_Classification_DataSet.json\") as f:\n",
    "    for line in f:\n",
    "        raw_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the data to extract the news contents & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents=[]\n",
    "for i in range(0,7600):\n",
    "    contents.append(raw_data[i][\"content\"])\n",
    "label=[]\n",
    "for i in range(0,7600):\n",
    "    label.append(raw_data[i][\"annotation\"][\"label\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label = np.array(list(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_label, converted_array_label = np.unique(label, return_inverse=True) #Indexing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = np.array(list(contents)) # Creating a numpy array of the contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vectorize the news contents and create a sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = contents\n",
    "vectorizer = CountVectorizer()\n",
    "new_content=vectorizer.fit_transform(corpus).todense().tolist()\n",
    "new_content_array=np.array(list(new_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split of the data in 90:10 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "label_train,label_test,content_train,content_test=train_test_split(converted_array_label,new_content_array,test_size=0.1,random_state=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vectorize the news labels with \"one-hot\" encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=4):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "# Our vectorized training labels\n",
    "one_hot_train_labels = to_one_hot(label_train)\n",
    "# Our vectorized test labels\n",
    "one_hot_test_labels = to_one_hot(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "one_hot_train_labels = to_categorical(label_train)\n",
    "one_hot_test_labels = to_categorical(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After parsing and Train-test split we have the data as follows:(With 20031 unique words in the contents and 4 unique labels)<br>\n",
    "So, our input is a (20031 x 1) boolean vector which correspond to a perticular news content.<br>\n",
    "And, our output is a (4 x 1) boolean vector which correspond to a perticular news lebel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6840, 4)\n",
      "(760, 4)\n",
      "(6840, 20031)\n",
      "(760, 20031)\n"
     ]
    }
   ],
   "source": [
    "print(one_hot_train_labels.shape) #Train labels\n",
    "print(one_hot_test_labels.shape) # Test labels\n",
    "print(content_train.shape) #Train contents\n",
    "print(content_test.shape) #Test contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating CV score (10-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Using Sigmoid as activation function at all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(40, activation='sigmoid', input_shape=(20031,)))\n",
    "    model.add(layers.Dense(40, activation='sigmoid'))\n",
    "    model.add(layers.Dense(4, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=create_network_1, \n",
    "                                 epochs=10, \n",
    "                                 batch_size=512, \n",
    "                                 verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.84064327, 0.86695907, 0.85672514, 0.83333333, 0.82309942,\n",
       "       0.82602339, 0.85818713, 0.81432748, 0.86403509, 0.83040936])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(neural_network,content_train,one_hot_train_labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6840/6840 [==============================] - 3s 474us/step - loss: 1.3997 - acc: 0.2519\n",
      "Epoch 2/10\n",
      "6840/6840 [==============================] - 2s 333us/step - loss: 1.3456 - acc: 0.3876\n",
      "Epoch 3/10\n",
      "6840/6840 [==============================] - 2s 300us/step - loss: 1.3018 - acc: 0.8069\n",
      "Epoch 4/10\n",
      "6840/6840 [==============================] - 2s 290us/step - loss: 1.2394 - acc: 0.8637\n",
      "Epoch 5/10\n",
      "6840/6840 [==============================] - 2s 308us/step - loss: 1.1604 - acc: 0.8762\n",
      "Epoch 6/10\n",
      "6840/6840 [==============================] - 2s 299us/step - loss: 1.0727 - acc: 0.8772\n",
      "Epoch 7/10\n",
      "6840/6840 [==============================] - 2s 304us/step - loss: 0.9813 - acc: 0.8902\n",
      "Epoch 8/10\n",
      "6840/6840 [==============================] - 2s 308us/step - loss: 0.8902 - acc: 0.8944\n",
      "Epoch 9/10\n",
      "6840/6840 [==============================] - 2s 277us/step - loss: 0.8015 - acc: 0.9028\n",
      "Epoch 10/10\n",
      "6840/6840 [==============================] - 2s 274us/step - loss: 0.7173 - acc: 0.9082\n",
      "760/760 [==============================] - 1s 1ms/step\n",
      "[0.7746408493895279, 0.8236842098988985]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(40, activation='sigmoid', input_shape=(20031,)))\n",
    "model.add(layers.Dense(40, activation='sigmoid'))\n",
    "model.add(layers.Dense(4, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(content_train,one_hot_train_labels,epochs = 10,batch_size = 512)\n",
    "results = model.evaluate(content_test,one_hot_test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8400154147966452\n",
      "Recall:  0.8408875957348906\n",
      "F1 score:  0.838879032179674\n"
     ]
    }
   ],
   "source": [
    "label_pred_1 = model.predict(content_test)\n",
    "label_pred_1 = np.argmax(label_pred_1, axis=1)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(label_test, label_pred_1, average='macro')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Using SeLU as activation function and softmax at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(40, activation='selu', input_shape=(20031,)))\n",
    "    model.add(layers.Dense(40, activation='selu'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=create_network_2, \n",
    "                                 epochs=10, \n",
    "                                 batch_size=512, \n",
    "                                 verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.875731  , 0.86111111, 0.85526316, 0.86695906, 0.86549707,\n",
       "       0.84064328, 0.86695906, 0.82748538, 0.86842105, 0.8494152 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(neural_network,content_train,one_hot_train_labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6840/6840 [==============================] - 4s 587us/step - loss: 0.8606 - acc: 0.7586\n",
      "Epoch 2/10\n",
      "6840/6840 [==============================] - 2s 279us/step - loss: 0.3461 - acc: 0.9231\n",
      "Epoch 3/10\n",
      "6840/6840 [==============================] - 2s 277us/step - loss: 0.1939 - acc: 0.9585\n",
      "Epoch 4/10\n",
      "6840/6840 [==============================] - 2s 293us/step - loss: 0.1113 - acc: 0.9784\n",
      "Epoch 5/10\n",
      "6840/6840 [==============================] - 2s 293us/step - loss: 0.0611 - acc: 0.9905\n",
      "Epoch 6/10\n",
      "6840/6840 [==============================] - 2s 278us/step - loss: 0.0324 - acc: 0.9961\n",
      "Epoch 7/10\n",
      "6840/6840 [==============================] - 2s 275us/step - loss: 0.0173 - acc: 0.9978\n",
      "Epoch 8/10\n",
      "6840/6840 [==============================] - 2s 296us/step - loss: 0.0093 - acc: 0.9993\n",
      "Epoch 9/10\n",
      "6840/6840 [==============================] - 2s 292us/step - loss: 0.0049 - acc: 0.9996\n",
      "Epoch 10/10\n",
      "6840/6840 [==============================] - 2s 293us/step - loss: 0.0031 - acc: 0.9996\n",
      "760/760 [==============================] - 1s 1ms/step\n",
      "[0.6266005139601858, 0.8539473684210527]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(40, activation='selu', input_shape=(20031,)))\n",
    "model.add(layers.Dense(40, activation='selu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(content_train,one_hot_train_labels,epochs = 10,batch_size = 512)\n",
    "results = model.evaluate(content_test,one_hot_test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8545691266786422\n",
      "Recall:  0.8558938919379728\n",
      "F1 score:  0.8549979901282609\n"
     ]
    }
   ],
   "source": [
    "label_pred_2 = model.predict(content_test)\n",
    "label_pred_2 = np.argmax(label_pred_2, axis=1)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(label_test, label_pred_2, average='macro')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Using Sigmoid as activation function and softmax in output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_3():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(40, activation='sigmoid', input_shape=(20031,)))\n",
    "    model.add(layers.Dense(40, activation='sigmoid'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=create_network_3, \n",
    "                                 epochs=10, \n",
    "                                 batch_size=512, \n",
    "                                 verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81871345, 0.86988304, 0.83625731, 0.85672514, 0.84210526,\n",
       "       0.82309941, 0.86695906, 0.83040935, 0.85818713, 0.83040935])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(neural_network,content_train,one_hot_train_labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6840/6840 [==============================] - 4s 593us/step - loss: 1.3652 - acc: 0.4183\n",
      "Epoch 2/10\n",
      "6840/6840 [==============================] - 2s 295us/step - loss: 1.3024 - acc: 0.7392\n",
      "Epoch 3/10\n",
      "6840/6840 [==============================] - 2s 280us/step - loss: 1.2287 - acc: 0.8212\n",
      "Epoch 4/10\n",
      "6840/6840 [==============================] - 2s 280us/step - loss: 1.1380 - acc: 0.8635\n",
      "Epoch 5/10\n",
      "6840/6840 [==============================] - 2s 289us/step - loss: 1.0361 - acc: 0.8844\n",
      "Epoch 6/10\n",
      "6840/6840 [==============================] - 2s 300us/step - loss: 0.9269 - acc: 0.8905\n",
      "Epoch 7/10\n",
      "6840/6840 [==============================] - 2s 290us/step - loss: 0.8173 - acc: 0.9001\n",
      "Epoch 8/10\n",
      "6840/6840 [==============================] - 2s 298us/step - loss: 0.7140 - acc: 0.9042\n",
      "Epoch 9/10\n",
      "6840/6840 [==============================] - 2s 286us/step - loss: 0.6212 - acc: 0.9120\n",
      "Epoch 10/10\n",
      "6840/6840 [==============================] - 2s 283us/step - loss: 0.5393 - acc: 0.9167\n",
      "760/760 [==============================] - 1s 1ms/step\n",
      "[0.6285303285247401, 0.8565789473684211]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(40, activation='sigmoid', input_shape=(20031,)))\n",
    "model.add(layers.Dense(40, activation='sigmoid'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(content_train,one_hot_train_labels,epochs = 10,batch_size = 512)\n",
    "results = model.evaluate(content_test,one_hot_test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8545691266786422\n",
      "Recall:  0.8558938919379728\n",
      "F1 score:  0.8549979901282609\n"
     ]
    }
   ],
   "source": [
    "label_pred_3 = model.predict(content_test)\n",
    "label_pred_3 = np.argmax(label_pred_3, axis=1)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(label_test, label_pred_2, average='macro')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Using ReLU as activation function and softmax in output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_4():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(40, activation='relu', input_shape=(20031,)))\n",
    "    model.add(layers.Dense(40, activation='relu'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=create_network_4, \n",
    "                                 epochs=10, \n",
    "                                 batch_size=512, \n",
    "                                 verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86842105, 0.875731  , 0.86842105, 0.87573099, 0.87573099,\n",
       "       0.84941521, 0.86988304, 0.84356725, 0.86111111, 0.85380117])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(neural_network,content_train,one_hot_train_labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6840/6840 [==============================] - 5s 753us/step - loss: 1.1488 - acc: 0.7105\n",
      "Epoch 2/10\n",
      "6840/6840 [==============================] - 2s 297us/step - loss: 0.6323 - acc: 0.9061\n",
      "Epoch 3/10\n",
      "6840/6840 [==============================] - 2s 295us/step - loss: 0.3779 - acc: 0.9336\n",
      "Epoch 4/10\n",
      "6840/6840 [==============================] - 2s 278us/step - loss: 0.2450 - acc: 0.9538\n",
      "Epoch 5/10\n",
      "6840/6840 [==============================] - 2s 300us/step - loss: 0.1634 - acc: 0.9686\n",
      "Epoch 6/10\n",
      "6840/6840 [==============================] - 2s 326us/step - loss: 0.1069 - acc: 0.9817\n",
      "Epoch 7/10\n",
      "6840/6840 [==============================] - 2s 284us/step - loss: 0.0693 - acc: 0.9885\n",
      "Epoch 8/10\n",
      "6840/6840 [==============================] - 2s 314us/step - loss: 0.0431 - acc: 0.9943\n",
      "Epoch 9/10\n",
      "6840/6840 [==============================] - 2s 295us/step - loss: 0.0262 - acc: 0.9965\n",
      "Epoch 10/10\n",
      "6840/6840 [==============================] - 2s 280us/step - loss: 0.0158 - acc: 0.9987\n",
      "760/760 [==============================] - 1s 2ms/step\n",
      "[0.5215951213711186, 0.8552631578947368]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(40, activation='relu', input_shape=(20031,)))\n",
    "model.add(layers.Dense(40, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(content_train,one_hot_train_labels,epochs = 10,batch_size = 512)\n",
    "results = model.evaluate(content_test,one_hot_test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8545691266786422\n",
      "Recall:  0.8558938919379728\n",
      "F1 score:  0.8549979901282609\n"
     ]
    }
   ],
   "source": [
    "label_pred_4 = model.predict(content_test)\n",
    "label_pred_4 = np.argmax(label_pred_4, axis=1)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(label_test, label_pred_2, average='macro')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Using tanH as activation function and softmax in output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_5():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(40, activation='tanh', input_shape=(20031,)))\n",
    "    model.add(layers.Dense(40, activation='tanh'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=create_network_5, \n",
    "                                 epochs=10, \n",
    "                                 batch_size=512, \n",
    "                                 verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87134503, 0.86695907, 0.87280702, 0.87134503, 0.88304093,\n",
       "       0.84502924, 0.86988304, 0.83333333, 0.86842105, 0.84502923])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(neural_network,content_train,one_hot_train_labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6840/6840 [==============================] - 5s 722us/step - loss: 0.9577 - acc: 0.7579\n",
      "Epoch 2/10\n",
      "6840/6840 [==============================] - 2s 292us/step - loss: 0.4687 - acc: 0.9054\n",
      "Epoch 3/10\n",
      "6840/6840 [==============================] - 2s 278us/step - loss: 0.2917 - acc: 0.9382\n",
      "Epoch 4/10\n",
      "6840/6840 [==============================] - 2s 290us/step - loss: 0.1908 - acc: 0.9592\n",
      "Epoch 5/10\n",
      "6840/6840 [==============================] - 2s 283us/step - loss: 0.1242 - acc: 0.9747\n",
      "Epoch 6/10\n",
      "6840/6840 [==============================] - 2s 282us/step - loss: 0.0790 - acc: 0.9861\n",
      "Epoch 7/10\n",
      "6840/6840 [==============================] - 2s 299us/step - loss: 0.0490 - acc: 0.9923\n",
      "Epoch 8/10\n",
      "6840/6840 [==============================] - 2s 299us/step - loss: 0.0291 - acc: 0.9969\n",
      "Epoch 9/10\n",
      "6840/6840 [==============================] - 2s 276us/step - loss: 0.0175 - acc: 0.9982\n",
      "Epoch 10/10\n",
      "6840/6840 [==============================] - 2s 287us/step - loss: 0.0108 - acc: 0.9993\n",
      "760/760 [==============================] - 1s 2ms/step\n",
      "[0.5286685074630536, 0.8578947368421053]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(40, activation='tanh', input_shape=(20031,)))\n",
    "model.add(layers.Dense(40, activation='tanh'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(content_train,one_hot_train_labels,epochs = 10,batch_size = 512)\n",
    "results = model.evaluate(content_test,one_hot_test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8545691266786422\n",
      "Recall:  0.8558938919379728\n",
      "F1 score:  0.8549979901282609\n"
     ]
    }
   ],
   "source": [
    "label_pred_5 = model.predict(content_test)\n",
    "label_pred_5 = np.argmax(label_pred_5, axis=1)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(label_test, label_pred_2, average='macro')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
